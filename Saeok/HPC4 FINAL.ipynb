{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN45w72mfmkoFfUxQFC/Q2K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0ojRYtd4NBX","executionInfo":{"status":"ok","timestamp":1712035470990,"user_tz":-330,"elapsed":17,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"aea2e363-3b55-4869-c4c7-2b2673cc1d1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["!nvcc --version"]},{"cell_type":"code","source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Fk0d7Of4Zw7","executionInfo":{"status":"ok","timestamp":1712035494150,"user_tz":-330,"elapsed":20532,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"baa37deb-6257-4786-8c69-4973c0c64197"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-98dcdb_b\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-98dcdb_b\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 4664a4ef472c35ed55ab1a53c458aa48e6f9919d\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: nvcc4jupyter\n","  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.0-py3-none-any.whl size=9547 sha256=15f657626f5c8a90f3e88c756de6b1b0dae55f253bb213026a351a0a360edb8c\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7hr5coar/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built nvcc4jupyter\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.0\n"]}]},{"cell_type":"code","source":["%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7ubqw2h4iS3","executionInfo":{"status":"ok","timestamp":1712035494151,"user_tz":-330,"elapsed":5,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"18cd4e01-149c-4d7c-d348-39307ea36449"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Source files will be saved in \"/tmp/tmppg5u8it4\".\n"]}]},{"cell_type":"code","source":["Write a CUDA Program for Addition of two large vectors\n"],"metadata":{"id":"8E9lbyRk4liY","colab":{"base_uri":"https://localhost:8080/","height":110},"executionInfo":{"status":"error","timestamp":1712035501013,"user_tz":-330,"elapsed":8,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"cea14d04-43e7-464b-d788-fefb5e85e349"},"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-4-9c085d438d70>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-9c085d438d70>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Write a CUDA Program for Addition of two large vectors\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","#define N 1000000\n","\n","// CUDA kernel for vector addition\n","__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n","    int i = blockDim.x * blockIdx.x + threadIdx.x;\n","    if (i < n) {\n","        c[i] = a[i] + b[i];\n","    }\n","}\n","\n","int main() {\n","    // Host vectors\n","    int *h_a, *h_b, *h_c;\n","    // Device vectors\n","    int *d_a, *d_b, *d_c;\n","    // Vector size\n","    int size = N * sizeof(int);\n","    // Allocate memory for host vectors\n","    h_a = (int *)malloc(size);\n","    h_b = (int *)malloc(size);\n","    h_c = (int *)malloc(size);\n","    // Initialize host vectors\n","    for (int i = 0; i < N; ++i) {\n","        h_a[i] = i;\n","        h_b[i] = i * 2;\n","    }\n","    // Allocate memory for device vectors\n","    cudaMalloc((void **)&d_a, size);\n","    cudaMalloc((void **)&d_b, size);\n","    cudaMalloc((void **)&d_c, size);\n","    // Copy host vectors to device\n","    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n","    // Define grid and block size\n","    dim3 dimGrid(ceil(N / 256.0), 1, 1);\n","    dim3 dimBlock(256, 1, 1);\n","    // Launch vectorAdd kernel on GPU\n","    vectorAdd<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n","    // Copy result from device to host\n","    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n","    // Verify the result\n","    for (int i = 0; i < 10; ++i) {\n","        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_a[i] + h_b[i]);\n","    }\n","    // Free device memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","    // Free host memory\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","    return 0;\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MX46RtHj4t3K","executionInfo":{"status":"ok","timestamp":1712035508685,"user_tz":-330,"elapsed":3439,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"14c6c4fc-970c-4539-9763-17eeca4e876b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0 + 0 = 0\n","1 + 2 = 3\n","2 + 4 = 6\n","3 + 6 = 9\n","4 + 8 = 12\n","5 + 10 = 15\n","6 + 12 = 18\n","7 + 14 = 21\n","8 + 16 = 24\n","9 + 18 = 27\n","\n"]}]},{"cell_type":"code","source":["\n","%%cuda\n","// Name: Pushkar Kasar\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","#define N 32\n","\n","// CUDA kernel for matrix multiplication\n","__global__ void matrixMul(int *a, int *b, int *c, int n) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","\n","    if (row < n && col < n) {\n","        int sum = 0;\n","        for (int i = 0; i < n; ++i) {\n","            sum += a[row * n + i] * b[i * n + col];\n","        }\n","        c[row * n + col] = sum;\n","    }\n","}\n","\n","int main() {\n","    // Matrix dimensions\n","    int size = N * N * sizeof(int);\n","\n","    // Host matrices\n","    int *h_a, *h_b, *h_c;\n","\n","    // Device matrices\n","    int *d_a, *d_b, *d_c;\n","\n","    // Allocate memory for host matrices\n","    h_a = (int *)malloc(size);\n","    h_b = (int *)malloc(size);\n","    h_c = (int *)malloc(size);\n","\n","    // Initialize host matrices\n","    for (int i = 0; i < N * N; ++i) {\n","        h_a[i] = i;\n","        h_b[i] = i * 2;\n","    }\n","\n","    // Allocate memory for device matrices\n","    cudaMalloc((void **)&d_a, size);\n","    cudaMalloc((void **)&d_b, size);\n","    cudaMalloc((void **)&d_c, size);\n","\n","    // Copy host matrices to device\n","    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n","\n","    // Define grid and block size\n","    dim3 dimGrid(ceil(N / 16.0), ceil(N / 16.0), 1);\n","    dim3 dimBlock(16, 16, 1);\n","\n","    // Launch matrixMul kernel on GPU\n","    matrixMul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n","\n","    // Copy result from device to host\n","    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n","\n","    // Print the result for verification\n","    for (int i = 0; i < 4; ++i) {\n","        for (int j = 0; j < 4; ++j) {\n","            printf(\"%d \", h_c[i * N + j]);\n","        }\n","        printf(\"\\n\");\n","    }\n","\n","    // Free device memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","\n","    // Free host memory\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","\n","    return 0;\n","}\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n2p42Kku5Qnm","executionInfo":{"status":"ok","timestamp":1712035512173,"user_tz":-330,"elapsed":1575,"user":{"displayName":"Omkar Katekar","userId":"12680260753264667966"}},"outputId":"2c0a4df7-2f27-41a6-b5b1-2fa2329efa86"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["666624 667616 668608 669600 \n","1682432 1685472 1688512 1691552 \n","2698240 2703328 2708416 2713504 \n","3714048 3721184 3728320 3735456 \n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u4td6o-u7Ozk"},"execution_count":null,"outputs":[]}]}