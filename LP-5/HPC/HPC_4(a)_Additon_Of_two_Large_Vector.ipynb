{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRUo8uXQ4qjN","executionInfo":{"status":"ok","timestamp":1713115777248,"user_tz":-330,"elapsed":17,"user":{"displayName":"Pratik Mehakare","userId":"09137431865528199563"}},"outputId":"a72ec41e-8715-4ea1-8507-c4f5ba9f53f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}],"source":["#HPC_4A\n","# Write a CUDA Program for :\n","# 1. Addition of two large vectors\n","\n","\n","!nvcc --version\n"]},{"cell_type":"code","source":["!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iu9woQ7G5d-2","executionInfo":{"status":"ok","timestamp":1713115797550,"user_tz":-330,"elapsed":16821,"user":{"displayName":"Pratik Mehakare","userId":"09137431865528199563"}},"outputId":"270fcdf5-59a0-4e4f-b45e-ba1dc0da1ea7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n","  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-u707d8b1\n","  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-u707d8b1\n","  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: nvcc4jupyter\n","  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=655723c0d2f4841dd76e45e772f96358a5fda83aba7888a669bf1eb2bb64257b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-pf2870ee/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n","Successfully built nvcc4jupyter\n","Installing collected packages: nvcc4jupyter\n","Successfully installed nvcc4jupyter-1.2.1\n"]}]},{"cell_type":"code","source":["%load_ext nvcc4jupyter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcqml7sx7G_U","executionInfo":{"status":"ok","timestamp":1713115801211,"user_tz":-330,"elapsed":12,"user":{"displayName":"Pratik Mehakare","userId":"09137431865528199563"}},"outputId":"59d351f8-8329-40a6-e93f-336e8ada2cee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected platform \"Colab\". Running its setup...\n","Source files will be saved in \"/tmp/tmp0b45xc1s\".\n"]}]},{"cell_type":"code","source":["%%cuda\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda_runtime.h>\n","\n","#define N 1000000\n","\n","// CUDA kernel for vector addition\n","__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n","    int i = blockDim.x * blockIdx.x + threadIdx.x;\n","    if (i < n) {\n","        c[i] = a[i] + b[i];\n","    }\n","}\n","\n","int main() {\n","    // Host vectors\n","    int *h_a, *h_b, *h_c;\n","\n","    // Device vectors\n","    int *d_a, *d_b, *d_c;\n","\n","    // Vector size\n","    int size = N * sizeof(int);\n","\n","    // Allocate memory for host vectors\n","    h_a = (int *)malloc(size);\n","    h_b = (int *)malloc(size);\n","    h_c = (int *)malloc(size);\n","\n","    // Initialize host vectors\n","    for (int i = 0; i < N; ++i) {\n","        h_a[i] = i;\n","        h_b[i] = i * 2;\n","    }\n","\n","    // Allocate memory for device vectors\n","    cudaMalloc((void **)&d_a, size);\n","    cudaMalloc((void **)&d_b, size);\n","    cudaMalloc((void **)&d_c, size);\n","\n","    // Copy host vectors to device\n","    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n","\n","    // Define grid and block size\n","    dim3 dimGrid(ceil(N / 256.0), 1, 1);\n","    dim3 dimBlock(256, 1, 1);\n","\n","    // Launch vectorAdd kernel on GPU\n","    vectorAdd<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n","\n","    // Copy result from device to host\n","    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n","\n","    // Verify the result\n","    for (int i = 0; i < 10; ++i) {\n","        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n","    }\n","\n","    // Free device memory\n","    cudaFree(d_a);\n","    cudaFree(d_b);\n","    cudaFree(d_c);\n","\n","    // Free host memory\n","    free(h_a);\n","    free(h_b);\n","    free(h_c);\n","\n","    return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_Ta6xgv6UfI","executionInfo":{"status":"ok","timestamp":1713115808332,"user_tz":-330,"elapsed":1780,"user":{"displayName":"Pratik Mehakare","userId":"09137431865528199563"}},"outputId":"a2d3140d-5003-4ea3-eafd-94b3c6e20db0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 + 0 = 0\n","1 + 2 = 3\n","2 + 4 = 6\n","3 + 6 = 9\n","4 + 8 = 12\n","5 + 10 = 15\n","6 + 12 = 18\n","7 + 14 = 21\n","8 + 16 = 24\n","9 + 18 = 27\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gdAMazQu-yge"},"execution_count":null,"outputs":[]}]}